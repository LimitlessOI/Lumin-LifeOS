# ğŸ‘€ How to See Open Source Council Working in Build Logs

## Quick Test

### Step 1: Start Your Server

```bash
cd /Users/adamhopkins/Projects/Lumin-LifeOS
npm start
```

**Look for this in startup logs:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âœ… [OPEN SOURCE COUNCIL] INITIALIZED                                              â•‘
â•‘    Status: Ready to route tasks to local Ollama models                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Step 2: Make a Test Call

**In a new terminal**, run:

```bash
curl -X POST http://localhost:8080/api/v1/chat \
  -H 'x-command-key: MySecretKey2025LifeOS' \
  -H 'Content-Type: application/json' \
  -d '{
    "message": "Hello, test the Open Source Council",
    "member": "ollama_llama",
    "useOpenSourceCouncil": true
  }'
```

### Step 3: Watch Your Server Logs

**You should see these logs appear:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ†“ [OPEN SOURCE COUNCIL] ACTIVATED - Using local Ollama models (FREE)            â•‘
â•‘    Reason: Explicit opt-in                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”„ [OSC] Routing task: Hello, test the Open Source Council...
    Task Type: auto-detect
    Complexity: SIMPLE (single model)
    Prompt Length: 40 chars

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸ§  [OPEN SOURCE COUNCIL ROUTER] Starting task routing                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ [OSC] Detected task type: general
    Specialization: General purpose tasks
    Primary models: ollama_llama, ollama_phi3
    Backup models: ollama_deepseek

âš¡ [OSC] Task is SIMPLE (single model execution)

ğŸ¯ [OSC] Executing with single model (task: General purpose tasks)
    Available models: ollama_llama, ollama_phi3
    Trying primary models first...

    ğŸ”„ Trying ollama_llama...

ğŸ†“ [OLLAMA] Calling local model: llama3.2:1b
    Endpoint: http://localhost:11434
    Member: ollama_llama
    Prompt length: 150 chars

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âœ… [OLLAMA] SUCCESS - Local model response received                            â•‘
â•‘    Model: llama3.2:1b                                                           â•‘
â•‘    Member: ollama_llama                                                         â•‘
â•‘    Response Time: 1234ms                                                        â•‘
â•‘    Response Length: 456 chars                                                  â•‘
â•‘    Cost: $0.00 (FREE - local Ollama)                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    âœ… ollama_llama succeeded in 1234ms

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âœ… [OSC] SINGLE MODEL EXECUTION SUCCESS                                         â•‘
â•‘    Model: ollama_llama                                                          â•‘
â•‘    Task: General purpose tasks                                                 â•‘
â•‘    Response Time: 1234ms                                                       â•‘
â•‘    Response Length: 456 chars                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ âœ… [OPEN SOURCE COUNCIL] SUCCESS                                                  â•‘
â•‘    Model: ollama_llama                                                          â•‘
â•‘    Task Type: general                                                           â•‘
â•‘    Response Time: 1234ms                                                       â•‘
â•‘    Cost: $0.00 (FREE - local Ollama)                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ§ª Automated Test Script

Run this to see OSC working:

```bash
./scripts/test-osc-visible.sh
```

This makes multiple test calls and you'll see all the OSC logs in your server console.

## âœ… What Success Looks Like

**If you see these logs, OSC is working:**

1. âœ… `[OPEN SOURCE COUNCIL] INITIALIZED` - At startup
2. âœ… `[OPEN SOURCE COUNCIL] ACTIVATED` - When OSC is used
3. âœ… `[OSC] Routing task` - Task routing started
4. âœ… `[OSC] Detected task type` - Task type detected
5. âœ… `[OLLAMA] Calling local model` - Ollama API call
6. âœ… `[OLLAMA] SUCCESS` - Response received
7. âœ… `[OPEN SOURCE COUNCIL] SUCCESS` - Final success

## âŒ Troubleshooting

### If you DON'T see OSC logs:

1. **Check if OSC is initialized:**
   - Look for `[OPEN SOURCE COUNCIL] INITIALIZED` at startup
   - If missing, OSC didn't load

2. **Check if OSC is being activated:**
   - Make sure you're using `"useOpenSourceCouncil": true` in your API call
   - Or set `MAX_DAILY_SPEND=0` to force OSC

3. **Check Ollama connection:**
   - Run: `node scripts/test-ollama-connection.js`
   - Should show Ollama is accessible

4. **Check server is running:**
   - Make sure `npm start` completed successfully
   - Look for "âœ… SYSTEM READY" message

## ğŸ“‹ Full Log Guide

See `docs/OSC_LOGS_GUIDE.md` for complete log reference.

---

**Ready to test?** Start your server and run the test script! ğŸš€

