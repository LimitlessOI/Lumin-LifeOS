/**
 * ╔══════════════════════════════════════════════════════════════════════════════════╗
 * ║                    MIGRATION GENERATOR                                             ║
 * ║                    Auto-generates database migrations from code                   ║
 * ╚══════════════════════════════════════════════════════════════════════════════════╝
 */

import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

export class MigrationGenerator {
  constructor(rootDir = null) {
    this.rootDir = rootDir || path.join(__dirname, '..');
    this.migrationsDir = path.join(this.rootDir, 'migrations');
  }

  /**
   * Detect database schema needs from code
   */
  async detectSchemaNeeds(code) {
    const needs = { 
      tables: new Set(), 
      columns: [], 
      indexes: [],
      constraints: []
    };
    
    // Detect pool.query patterns with SQL
    const queryRegex = /pool\.query\s*\(\s*`([^`]+)`/g;
    let match;
    
    while ((match = queryRegex.exec(code)) !== null) {
      const sql = match[1];
      
      // Detect table references (FROM, INTO, UPDATE, JOIN)
      const tablePatterns = [
        /FROM\s+["']?(\w+)["']?/gi,
        /INTO\s+["']?(\w+)["']?/gi,
        /UPDATE\s+["']?(\w+)["']?/gi,
        /JOIN\s+["']?(\w+)["']?/gi,
        /TABLE\s+["']?(\w+)["']?/gi,
        /CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?["']?(\w+)["']?/gi
      ];
      
      for (const pattern of tablePatterns) {
        let tableMatch;
        while ((tableMatch = pattern.exec(sql)) !== null) {
          const tableName = tableMatch[1];
          if (tableName && !['SELECT', 'INSERT', 'UPDATE', 'DELETE'].includes(tableName.toUpperCase())) {
            needs.tables.add(tableName);
          }
        }
      }
      
      // Detect column references
      const columnPattern = /(?:SELECT|INSERT|UPDATE|ALTER)\s+.*?(\w+)\s+(?:VARCHAR|TEXT|INTEGER|BIGINT|SERIAL|TIMESTAMP|BOOLEAN|JSONB)/gi;
      let columnMatch;
      while ((columnMatch = columnPattern.exec(sql)) !== null) {
        needs.columns.push({
          name: columnMatch[1],
          detectedFrom: sql.substring(0, 100)
        });
      }
    }
    
    // Also check for CREATE TABLE statements
    const createTableRegex = /CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?["']?(\w+)["']?\s*\(/gi;
    let createMatch;
    while ((createMatch = createTableRegex.exec(code)) !== null) {
      needs.tables.add(createMatch[1]);
    }
    
    return {
      tables: Array.from(needs.tables),
      columns: needs.columns,
      indexes: needs.indexes,
      constraints: needs.constraints
    };
  }

  /**
   * Generate migration file
   */
  async generateMigration(needs, description = 'auto_generated') {
    // Ensure migrations directory exists
    try {
      await fs.mkdir(this.migrationsDir, { recursive: true });
    } catch (e) {
      // Directory might already exist
    }
    
    const timestamp = Date.now();
    const safeDescription = description
      .replace(/[^a-zA-Z0-9_]/g, '_')
      .substring(0, 50);
    const filename = `${timestamp}_${safeDescription}.sql`;
    const filepath = path.join(this.migrationsDir, filename);
    
    let sql = `-- Migration: ${description}\n`;
    sql += `-- Generated: ${new Date().toISOString()}\n`;
    sql += `-- Auto-generated by MigrationGenerator\n\n`;
    
    // Generate CREATE TABLE statements
    for (const table of needs.tables) {
      sql += `-- Ensure ${table} table exists\n`;
      sql += `CREATE TABLE IF NOT EXISTS ${table} (\n`;
      sql += `  id SERIAL PRIMARY KEY,\n`;
      sql += `  created_at TIMESTAMPTZ DEFAULT NOW(),\n`;
      sql += `  updated_at TIMESTAMPTZ DEFAULT NOW()\n`;
      sql += `);\n\n`;
    }
    
    // Add indexes for common patterns
    for (const table of needs.tables) {
      sql += `-- Index for ${table}.created_at\n`;
      sql += `CREATE INDEX IF NOT EXISTS idx_${table}_created_at ON ${table}(created_at);\n\n`;
    }
    
    // Add updated_at trigger if not exists
    sql += `-- Function to update updated_at timestamp\n`;
    sql += `CREATE OR REPLACE FUNCTION update_updated_at_column()\n`;
    sql += `RETURNS TRIGGER AS $$\n`;
    sql += `BEGIN\n`;
    sql += `  NEW.updated_at = NOW();\n`;
    sql += `  RETURN NEW;\n`;
    sql += `END;\n`;
    sql += `$$ LANGUAGE plpgsql;\n\n`;
    
    // Add triggers for each table
    for (const table of needs.tables) {
      sql += `-- Trigger for ${table}.updated_at\n`;
      sql += `DROP TRIGGER IF EXISTS update_${table}_updated_at ON ${table};\n`;
      sql += `CREATE TRIGGER update_${table}_updated_at\n`;
      sql += `  BEFORE UPDATE ON ${table}\n`;
      sql += `  FOR EACH ROW\n`;
      sql += `  EXECUTE FUNCTION update_updated_at_column();\n\n`;
    }
    
    try {
      await fs.writeFile(filepath, sql, 'utf-8');
      console.log(`✅ [MIGRATION-GENERATOR] Created migration: ${filename}`);
      return { filename, filepath, sql };
    } catch (e) {
      console.error(`❌ [MIGRATION-GENERATOR] Failed to write migration: ${e.message}`);
      throw e;
    }
  }

  /**
   * Detect schema needs from multiple code files
   */
  async detectSchemaNeedsFromFiles(fileContents) {
    const allNeeds = {
      tables: new Set(),
      columns: [],
      indexes: [],
      constraints: []
    };
    
    for (const content of Object.values(fileContents)) {
      const needs = await this.detectSchemaNeeds(content);
      needs.tables.forEach(t => allNeeds.tables.add(t));
      allNeeds.columns.push(...needs.columns);
      allNeeds.indexes.push(...needs.indexes);
      allNeeds.constraints.push(...needs.constraints);
    }
    
    return {
      tables: Array.from(allNeeds.tables),
      columns: allNeeds.columns,
      indexes: allNeeds.indexes,
      constraints: allNeeds.constraints
    };
  }

  /**
   * Check if migration already exists for a table
   */
  async migrationExists(tableName) {
    try {
      const files = await fs.readdir(this.migrationsDir);
      const tableRegex = new RegExp(tableName, 'i');
      return files.some(f => tableRegex.test(f));
    } catch {
      return false;
    }
  }
}

// Export singleton instance
export const migrationGenerator = new MigrationGenerator();
export default migrationGenerator;
