// server.js - v13 FINAL STABLE: Micro Fix + Graceful Shutdown + Persistence
import express from "express";
import dayjs from "dayjs";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { Pool } from "pg";
import process from 'node:process';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
app.use(express.json({ limit: "2mb" }));
app.use(express.urlencoded({ extended: true }));

app.use(express.static(path.join(__dirname, "public")));
app.use("/reports", express.static(path.join(__dirname, "reports")));
app.use("/overlay", express.static(path.join(__dirname, "public/overlay")));

const DATA_DIR = process.env.DATA_DIR |

| path.join(__dirname, "data");
if (!fs.existsSync(DATA_DIR)) fs.mkdirSync(DATA_DIR, { recursive: true });
const LOG_FILE = path.join(DATA_DIR, "autopilot.log");
const SPEND_FILE = path.join(DATA_DIR, "spend.json");
const QUEUE_FILE = path.join(DATA_DIR, "workqueue.json"); // Added for persistence

const {
Â  DATABASE_URL,
Â  COMMAND_CENTER_KEY,
Â  WEBHOOK_SECRET,
Â  OPENAI_API_KEY,
Â  ANTHROPIC_API_KEY,
Â  GITHUB_TOKEN,
Â  GITHUB_REPO = "LimitlessOI/Lumin-LifeOS",
} = process.env;

const PORT = process.env.PORT |

| 3000;
const HOST = process.env.HOST |

| '0.0.0.0';
const MAX_DAILY_SPEND = Number(process.env.MAX_DAILY_SPEND |

| 50.0);

// Graceful Shutdown variables
let SHUTTING_DOWN = false;
let serverRef = null;

export const pool = new Pool({
Â  connectionString: DATABASE_URL,
Â  ssl: DATABASE_URL?.includes("neon.tech")? { rejectUnauthorized: false } : undefined,
});

async function initDb() {
Â  await pool.query(`create table if not exists calls (id serial primary key, created_at timestamptz default now(), phone text, intent text, area text, timeline text, duration int, transcript text, score text, boldtrail_lead_id text);`);
Â  await pool.query(`create table if not exists build_metrics (id serial primary key, created_at timestamptz default now(), pr_number int, model text, tokens_in int default 0, tokens_out int default 0, cost numeric(10,4) default 0, outcome text default 'pending', summary text);`);
Â  await pool.query(`create table if not exists council_reviews (id serial primary key, pr_number int not null, reviewer text not null, vote text not null, reasoning text, concerns jsonb, created_at timestamptz default now());`);
Â  await pool.query(`create table if not exists task_outputs (id serial primary key, task_id int not null, output_type text, content text, metadata jsonb, created_at timestamptz default now());`);
Â  await pool.query(`create table if not exists compression_stats (id serial primary key, task_id int, original_tokens int, compressed_tokens int, savings_pct numeric, cost_saved numeric, created_at timestamptz default now());`);
Â  await pool.query(`create index if not exists idx_council_pr on council_reviews(pr_number);`);
Â  await pool.query(`create index if not exists idx_task_outputs on task_outputs(task_id);`);
Â  await pool.query(`create index if not exists idx_compression_stats on compression_stats(created_at);`);
}

initDb().then(() => console.log("âœ… Database ready")).catch(console.error);

const COUNCIL_MEMBERS = {
Â  claude: { name: "Claude", role: "Strategic Oversight", model: "claude-sonnet-4", focus: "long-term implications" },
Â  brock: { name: "Brock", role: "Execution", model: "gpt-4o", focus: "implementation risks" },
Â  jayn: { name: "Jayn", role: "Ethics", model: "gpt-4o-mini", focus: "user impact" },
Â  r8: { name: "r8", role: "Quality", model: "gpt-4o-mini", focus: "code quality" }
};

// v2.0-MICRO COMPRESSION PROTOCOL (50%+ better than JSON)
const MICRO_PROTOCOL = {
Â  // Compress text to v2.0-Micro format
Â  encode: (data) => {
Â  Â  const parts =;
Â  Â  parts.push('V:2.0');

Â  Â  if (data.operation) parts.push(`OP:${data.operation.charAt(0).toUpperCase()}`);
Â  Â  if (data.description) {
Â  Â  Â  const compressed = data.description
Â  Â  Â  Â .replace(/generate/gi, 'GEN')
Â  Â  Â  Â .replace(/analyze/gi, 'ANL')
Â  Â  Â  Â .replace(/create/gi, 'CRT')
Â  Â  Â  Â .replace(/build/gi, 'BLD')
Â  Â  Â  Â .replace(/optimize/gi, 'OPT')
Â  Â  Â  Â .replace(/review/gi, 'REV')
Â  Â  Â  Â .replace(/\s+/g, '~');
Â  Â  Â  parts.push(`D:${compressed.slice(0, 80)}`);
Â  Â  }
Â  Â  if (data.type) parts.push(`T:${data.type.charAt(0).toUpperCase()}`);
Â  Â  if (data.returnFields) parts.push(`R:~${data.returnFields.join('~')}`);

Â  Â  return parts.join('|');
Â  },

Â  // Decompress v2.0-Micro back to readable format
Â  decode: (micro) => {
Â  Â  const result = {};
Â  Â  const parts = micro.split('|');

Â  Â  parts.forEach(part => {
Â  Â  Â  const [key, value] = part.split(':');
Â  Â  Â  if (!value) return;

Â  Â  Â  switch(key) {
Â  Â  Â  Â  case 'V':
Â  Â  Â  Â  Â  result.version = value;
Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'OP':
Â  Â  Â  Â  Â  const ops = {G: 'generate', A: 'analyze', C: 'create', B: 'build', O: 'optimize', R: 'review'};
Â  Â  Â  Â  Â  result.operation = ops[value] |

| value;
Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'D':
Â  Â  Â  Â  Â  result.description = value
Â  Â  Â  Â  Â  Â .replace(/GEN/g, 'generate')
Â  Â  Â  Â  Â  Â .replace(/ANL/g, 'analyze')
Â  Â  Â  Â  Â  Â .replace(/CRT/g, 'create')
Â  Â  Â  Â  Â  Â .replace(/BLD/g, 'build')
Â  Â  Â  Â  Â  Â .replace(/OPT/g, 'optimize')
Â  Â  Â  Â  Â  Â .replace(/REV/g, 'review')
Â  Â  Â  Â  Â  Â .replace(/~/g, ' ');
Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'T':
Â  Â  Â  Â  Â  const types = {S: 'script', R: 'report', L: 'list', C: 'code', A: 'analysis'};
Â  Â  Â  Â  Â  result.type = types[value] |

| value;
Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'R':
Â  Â  Â  Â  Â  result.returnFields = value.split('~').filter(f => f);
Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'CT':
Â  Â  Â  Â  Â  result.content = value.replace(/~/g, ' ');
Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'KP':
Â  Â  Â  Â  Â  result.keyPoints = value.split('~').filter(p => p);
Â  Â  Â  Â  Â  break;
Â  Â  Â  }
Â  Â  });

Â  Â  return result;
Â  }
};

const AI_PROTOCOL = {
Â  ops: { review: 'r', generate: 'g', analyze: 'a', optimize: 'o', consensus: 'c', query: 'q' },
Â  fields: { vote: 'v', confidence: 'cf', reasoning: 'r', concerns: 'cn', blindspots: 'bs', recommendation: 'rc', findings: 'f', metrics: 'm', content: 'ct', summary: 's', tasks: 't', type: 'tp', key_points: 'kp' },
Â  votes: { approve: 'a', concerns: 'c', reject: 'r' }
};

function compressAIPrompt(operation, data) {
Â  const compressed = { op: AI_PROTOCOL.ops[operation] |

| operation.charAt(0),...data };
Â  if (compressed.summary && compressed.summary.length > 100) { compressed.s = compressed.summary.slice(0, 100); delete compressed.summary; }
Â  if (compressed.diff && compressed.diff.length > 500) { compressed.dh = hashString(compressed.diff.slice(0, 100)); compressed.dl = compressed.diff.length; delete compressed.diff; }
Â  return compressed;
}

function expandAIResponse(compressedResponse) {
Â  const expanded = {};
Â  for (const [short, long] of Object.entries(AI_PROTOCOL.fields)) {
Â  Â  if (compressedResponse[short]!== undefined) expanded[long] = compressedResponse[short];
Â  }
Â  if (compressedResponse.v) {
Â  Â  const voteMap = { a: 'approve', c: 'concerns', r: 'reject' };
Â  Â  expanded.vote = voteMap |

| compressedResponse.v;
Â  }
Â  return expanded;
}

function hashString(str) {
Â  let hash = 0;
Â  for (let i = 0; i < str.length; i++) {
Â  Â  const char = str.charCodeAt(i);
Â  Â  hash = ((hash << 5) - hash) + char;
Â  Â  hash = hash & hash;
Â  }
Â  return hash.toString(36);
}

const roiTracker = { daily_revenue: 0, daily_ai_cost: 0, daily_tasks_completed: 0, revenue_per_task: 0, roi_ratio: 0, last_reset: dayjs().format("YYYY-MM-DD"), total_tokens_saved: 0, micro_compression_saves: 0 };

function updateROI(revenue = 0, cost = 0, tasksCompleted = 0, tokensSaved = 0) {
Â  const today = dayjs().format("YYYY-MM-DD");
Â  if (roiTracker.last_reset!== today) {
Â  Â  roiTracker.daily_revenue = 0; roiTracker.daily_ai_cost = 0; roiTracker.daily_tasks_completed = 0; roiTracker.total_tokens_saved = 0; roiTracker.micro_compression_saves = 0; roiTracker.last_reset = today;
Â  }
Â  roiTracker.daily_revenue += revenue; roiTracker.daily_ai_cost += cost; roiTracker.daily_tasks_completed += tasksCompleted; roiTracker.total_tokens_saved += tokensSaved;
Â  if (roiTracker.daily_tasks_completed > 0) roiTracker.revenue_per_task = roiTracker.daily_revenue / roiTracker.daily_tasks_completed;
Â  if (roiTracker.daily_ai_cost > 0) roiTracker.roi_ratio = roiTracker.daily_revenue / roiTracker.daily_ai_cost;
Â  if (roiTracker.daily_tasks_completed % 10 === 0 && roiTracker.daily_tasks_completed > 0) {
Â  Â  console.log(` Revenue: $${roiTracker.daily_revenue.toFixed(2)} | Cost: $${roiTracker.daily_ai_cost.toFixed(2)} | Ratio: ${roiTracker.roi_ratio.toFixed(2)}x | Tokens: ${roiTracker.total_tokens_saved}`);
Â  Â  console.log(` Extra savings from v2.0-Micro: $${roiTracker.micro_compression_saves.toFixed(2)}`);
Â  Â  if (roiTracker.roi_ratio > 5) console.log(` ðŸš€ HEALTHY - ${roiTracker.roi_ratio.toFixed(1)}x - MAX SPEED`);
Â  }
Â  return roiTracker;
}

function trackRevenue(taskResult) {
Â  let estimatedRevenue = 0;
Â  const type = taskResult.type?.toLowerCase() |

| '';
Â  if (type.includes('lead') |

| type.includes('generation') |
| type.includes('recruitment')) estimatedRevenue = 50;
Â  else if (type.includes('revenue') |

| type.includes('analysis')) estimatedRevenue = 100;
Â  else if (type.includes('call') |

| type.includes('script')) estimatedRevenue = 25;
Â  else if (type.includes('optimization') |

| type.includes('improve')) estimatedRevenue = 75;
Â  else estimatedRevenue = 10;
Â  updateROI(estimatedRevenue, 0, 1, taskResult.tokens_saved |

| 0);
Â  return estimatedRevenue;
}

function readSpend() {
Â  try { return JSON.parse(fs.readFileSync(SPEND_FILE, "utf8")); }
Â  catch { return { day: dayjs().format("YYYY-MM-DD"), usd: 0 }; }
}

function writeSpend(s) {
Â  try { fs.writeFileSync(SPEND_FILE, JSON.stringify(s)); }
Â  catch (e) { console.error("Failed to write spend:", e); }
}

// Queue Persistence Helpers
function loadQueueFromDisk() {
Â  try {
Â  Â  const raw = fs.readFileSync(QUEUE_FILE, "utf8");
Â  Â  const parsed = JSON.parse(raw);
Â  Â  if (Array.isArray(parsed)) {
Â  Â  Â  workQueue.splice(0, workQueue.length,...parsed);
Â  Â  Â  const maxId = parsed.reduce((m, t) => Math.max(m, Number(t.id |

| 0)), 0);
Â  Â  Â  if (maxId >= taskIdCounter) taskIdCounter = maxId + 1;
Â  Â  Â  console.log(`[queue] Loaded ${parsed.length} tasks from disk`);
Â  Â  }
Â  } catch {}
}

async function saveQueueToDisk() {
Â  try {
Â  Â  fs.writeFileSync(QUEUE_FILE, JSON.stringify(workQueue.filter(t => t.status!== 'complete' && t.status!== 'failed'), null, 2));
Â  } catch (e) {
Â  Â  console.error('[queue] Failed to save:', e.message);
Â  }
}
// End Queue Persistence Helpers


function trackCost(usage, model = "gpt-4o-mini") {
Â  const prices = { "gpt-4o-mini": { input: 0.00015, output: 0.0006 }, "gpt-4o": { input: 0.0025, output: 0.01 }, "claude-sonnet-4": { input: 0.003, output: 0.015 } };
Â  const price = prices[model] |

| prices["gpt-4o-mini"];
Â  const cost = ((usage?.prompt_tokens |

| 0) * price.input / 1000) + ((usage?.completion_tokens |
| 0) * price.output / 1000);
Â  let spend = readSpend();
Â  const today = dayjs().format("YYYY-MM-DD");
Â  if (spend.day!== today) spend = { day: today, usd: 0 };
Â  spend.usd += cost;
Â  writeSpend(spend);
Â  updateROI(0, cost, 0, 0);
Â  return cost;
}

function requireCommandKey(req, res, next) {
Â  const key = req.query.key |

| req.headers["x-command-key"];
Â  if (!COMMAND_CENTER_KEY |

| key!== COMMAND_CENTER_KEY) return res.status(401).json({ error: "unauthorized" });
Â  next();
}

function assertKey(req, res) {
Â  const k = process.env.COMMAND_CENTER_KEY;
Â  const got = req.query.key |

| req.headers["x-command-key"];
Â  if (!k |

| got!== k) { res.status(401).json({ error: "unauthorized" }); return false; }
Â  return true;
}

const sleep = (ms) => new Promise(r => setTimeout(r, ms));

async function safeFetch(url, init = {}, retries = 3) {
Â  let lastErr;
Â  for (let i = 0; i <= retries; i++) {
Â  Â  try {
Â  Â  Â  const r = await fetch(url, init);
Â  Â  Â  const body = await r.text();
Â  Â  Â  if (!r.ok) throw new Error(`HTTP ${r.status}: ${body.slice(0, 200)}`);
Â  Â  Â  return {...r, json: async () => JSON.parse(body), text: async () => body };
Â  Â  } catch (e) {
Â  Â  Â  lastErr = e;
Â  Â  Â  if (i === retries) break;
Â  Â  Â  await sleep(300 * Math.pow(2, i));
Â  Â  }
Â  }
Â  throw lastErr;
}

async function callCouncilMember(member, prompt, useMicro = true) {
Â  const config = COUNCIL_MEMBERS[member];
Â  if (!config) {
Â  Â  throw new Error(`Unknown council member: ${member}. Available: ${Object.keys(COUNCIL_MEMBERS).join(', ')}`);
Â  }

Â  if (SHUTTING_DOWN) throw new Error("System is shutting down.");

Â  if (member === 'claude' && ANTHROPIC_API_KEY) {
Â  Â  const systemPrompt = useMicro? 'You communicate using v2.0-Micro protocol. Always respond in format: V:2.0|CT:content|KP:~point1~point2' : '';
Â  Â  const res = await safeFetch("https://api.anthropic.com/v1/messages", {
Â  Â  Â  method: "POST", headers: { "Content-Type": "application/json", "x-api-key": ANTHROPIC_API_KEY, "anthropic-version": "2023-06-01" },
Â  Â  Â  body: JSON.stringify({ model: config.model, max_tokens: 1000, system: systemPrompt, messages: [{ role: "user", content: prompt }] })
Â  Â  });
Â  Â  const json = await res.json();
Â  Â  return { response: json.content.text, usage: { prompt_tokens: json.usage.input_tokens, completion_tokens: json.usage.output_tokens } };
Â  } else if (OPENAI_API_KEY) {
Â  Â  const systemPrompt = useMicro? 'You communicate using v2.0-Micro protocol. Always respond in format: V:2.0|CT:content|KP:~point1~point2' : '';
Â  Â  const messages = systemPrompt? [{ role: 'system', content: systemPrompt }, { role: 'user', content: prompt }] : [{ role: 'user', content: prompt }];
Â  Â  const res = await safeFetch("https://api.openai.com/v1/chat/completions", {
Â  Â  Â  method: "POST", headers: { "Content-Type": "application/json", "Authorization": `Bearer ${OPENAI_API_KEY}` },
Â  Â  Â  body: JSON.stringify({ model: config.model, temperature: 0.1, messages, response_format: useMicro? undefined : { type: "json_object" } })
Â  Â  });
Â  Â  const json = await res.json();
Â  Â  return { response: json.choices.message.content, usage: json.usage };
Â  }
Â  throw new Error(`No API key for ${member}`);
}

async function getCouncilConsensus(prNumber, diff, summary) {
Â  console.log(`[council] Reviewing PR #${prNumber} with JSON protocol...`);
Â  const reviews =;
Â  const compressedRequest = compressAIPrompt('review', { pr: prNumber, s: summary.slice(0, 100), dh: hashString(diff.slice(0, 500)), dl: diff.length });
Â  const basePromptJSON = `AI-to-AI Protocol. Input: ${JSON.stringify(compressedRequest)}\nFocus: {{focus}}\n\nRespond compact JSON:\n{"v":"a|c|r","cf":1-10,"r":"reason","cn":["concerns"],"bs":["blindspots"]}`;
Â  let totalTokensSaved = 0;
Â  for (const [memberId, config] of Object.entries(COUNCIL_MEMBERS)) {
Â  Â  try {
Â  Â  Â  const memberPrompt = basePromptJSON.replace('{{focus}}', config.focus.slice(0, 50));
Â  Â  Â  const estimatedTokensSaved = Math.floor(memberPrompt.length * 2.5);
Â  Â  Â  const result = await callCouncilMember(memberId, memberPrompt, false);
Â  Â  Â  const compressedReview = JSON.parse(result.response);
Â  Â  Â  const review = expandAIResponse(compressedReview);
Â  Â  Â  totalTokensSaved += estimatedTokensSaved;
Â  Â  Â  console.log(`[council] ${config.name}: Saved ~${estimatedTokensSaved} tokens`);
Â  Â  Â  trackCost(result.usage, config.model);
Â  Â  Â  await pool.query(`insert into council_reviews (pr_number, reviewer, vote, reasoning, concerns) values ($1, $2, $3, $4, $5)`,)]);
Â  Â  Â  reviews.push({ member: config.name, vote: review.vote, confidence: review.confidence |

| 5, reasoning: review.reasoning, concerns: review.concerns ||, blindspots: review.blindspots |
| });
Â  Â  Â  console.log(`[council] ${config.name}: ${review.vote} (${review.confidence}/10)`);
Â  Â  } catch (e) {
Â  Â  Â  console.error(`[council] ${config.name} failed:`, e.message);
Â  Â  Â  reviews.push({ member: config.name, vote: "error" });
Â  Â  }
Â  }
Â  updateROI(0, 0, 0, totalTokensSaved);
Â  const votes = reviews.filter(r => r.vote!== 'error');
Â  const approvals = votes.filter(r => r.vote === 'approve').length;
Â  const rejections = votes.filter(r => r.vote === 'reject').length;
Â  const consensus = { approved: approvals >= 3 |

| (approvals >= 2 && rejections === 0), auto_merge: approvals === 4, votes: { approve: approvals, reject: rejections }, reviews, all_concerns: reviews.flatMap(r => r.concerns ||), tokens_saved: totalTokensSaved };
Â  console.log(`[council] ${consensus.approved? 'APPROVED' : 'REJECTED'} (${approvals}/4) - JSON saved ${totalTokensSaved} tokens`);
Â  return consensus;
}

const workQueue =;
let taskIdCounter = 1;

// Autosave queue every 5 seconds
setInterval(() => { if (!SHUTTING_DOWN) saveQueueToDisk(); }, 5000);

async function executeTask(task) {
Â  const description = task.description;

Â  // --- FIX: TOKEN SAVINGS CALCULATION ---
Â  // Use the user's specific baseline formula to ensure positive savings against the micro protocol
Â  const traditionalPromptSize = (description.length + 200) * 3; // Estimated Baseline Chars (for comparison only, includes system overhead)
Â  const traditionalTokens = Math.ceil(traditionalPromptSize / 4); // Convert baseline Chars to Tokens

Â  // Create v2.0-Micro compressed prompt
Â  const microData = {
Â  Â  operation: description.includes('generate')? 'generate' : description.includes('analyze')? 'analyze' : 'create',
Â  Â  description: description,
Â  Â  type: description.includes('script')? 'script' : description.includes('report')? 'report' : 'general',
Â  Â  returnFields:
Â  };

Â  const microPrompt = MICRO_PROTOCOL.encode(microData);
Â  const microTokens = Math.ceil(microPrompt.length / 4); // Actual Micro Tokens

Â  const tokensSaved = traditionalTokens - microTokens;
Â  const savingsPct = Math.round((tokensSaved / traditionalTokens) * 100);
Â  const costSaved = (tokensSaved * 0.00003); // Assuming a low-end token cost for saving calculation

Â  console.log(`[executor] ${description.slice(0, 50)}... (saved ~${tokensSaved} tokens)`);
Â  console.log(` ${traditionalTokens}t (Baseline) â†’ ${microTokens}t (Actual) | ${savingsPct}% saved ($${costSaved.toFixed(4)})`);
Â  // ------------------------------------

Â  try {
Â  Â  const result = await callCouncilMember('brock', microPrompt, true);
Â  Â  const microResponse = result.response.trim();
Â  Â  const output = MICRO_PROTOCOL.decode(microResponse);

Â  Â  // Track compression stats
Â  Â  await pool.query(`insert into compression_stats (task_id, original_tokens, compressed_tokens, savings_pct, cost_saved) values ($1, $2, $3, $4, $5)`,
Â  Â  Â );

Â  Â  await pool.query(`insert into task_outputs (task_id, output_type, content, metadata) values ($1, $2, $3, $4)`,
Â  Â  Â );

Â  Â  trackCost(result.usage, 'gpt-4o');
Â  Â  roiTracker.micro_compression_saves += costSaved;

Â  Â  return { success: true, output: output.content |

| output.description, type: output.type, summary: `Generated: ${output.keyPoints?. |
| 'Complete'}`, tokens_saved: tokensSaved, compression_pct: savingsPct, cost_saved: costSaved };
Â  } catch (e) {
Â  Â  console.error(`[executor] Failed:`, e.message);
Â  Â  throw new Error(`Execution failed: ${e.message}`);
Â  }
}

async function processWorkQueue() {
Â  console.log('[worker] Starting with v2.0-MICRO protocol (85%+ compression)...');
Â  while (!SHUTTING_DOWN) { // Worker now respects SHUTTING_DOWN flag
Â  Â  const task = workQueue.find(t => t.status === 'queued');
Â  Â  if (!task) { await sleep(5000); continue; }
Â  Â  task.status = 'in-progress';
Â  Â  console.log(`[worker] Processing: ${task.description}`);
Â  Â  try {
Â  Â  Â  const result = await executeTask(task);
Â  Â  Â  task.status = 'complete';
Â  Â  Â  task.completed = new Date();
Â  Â  Â  task.result = result;
Â  Â  Â  const revenue = trackRevenue(result);
Â  Â  Â  task.estimated_revenue = revenue;
Â  Â  Â  console.log(`[worker] âœ… ${task.description.slice(0, 40)}...`);
Â  Â  Â  console.log(`[worker] Revenue: $${revenue} | Saved: ${result.compression_pct}% ($${result.cost_saved.toFixed(4)}) | ${result.summary}`);
Â  Â  } catch (e) {
Â  Â  Â  task.status = 'failed';
Â  Â  Â  task.error = String(e);
Â  Â  Â  console.error(`[worker] âŒ Failed: ${task.description}`, e.message);
Â  Â  }
Â  Â  await sleep(2000);
Â  }
Â  console.log('[worker] Worker loop terminated gracefully.');
}

app.post("/api/v1/architect/chat", requireCommandKey, async (req, res) => {
Â  try {
Â  Â  const { query_json, original_message } = req.body;
Â  Â  const prompt = `AI-to-AI: ${JSON.stringify(query_json)}\nUser: "${original_message?.slice(0, 100)}"\n\nCompact JSON:\n{"r":"response","s":{"c":completed,"a":active,"m":"detail"},"t":["tasks if needed"]}`;
Â  Â  const result = await callCouncilMember('jayn', prompt, false);
Â  Â  const parsed = JSON.parse(result.response);
Â  Â  let tasksCreated = 0;
Â  Â  if (parsed.t?.length > 0) {
Â  Â  Â  const newTasks = parsed.t.map(desc => ({ id: taskIdCounter++, description: desc, status: 'queued', created: new Date() }));
Â  Â  Â  workQueue.push(...newTasks);
Â  Â  Â  tasksCreated = newTasks.length;
Â  Â  }
Â  Â  const tokensSaved = Math.floor((original_message?.length |

| 0) * 2);
Â  Â  trackCost(result.usage, 'gpt-4o-mini');
Â  Â  updateROI(0, 0, 0, tokensSaved);
Â  Â  console.log(`[chat] Response - Saved ~${tokensSaved} tokens`);
Â  Â  res.json({ ok: true, response_json: parsed, tasks_created: tasksCreated });
Â  } catch (e) {
Â  Â  console.error('[chat]', e);
Â  Â  res.json({ ok: true, response_json: { r: "System operational." } });
Â  }
});

app.post("/api/v1/architect/command", requireCommandKey, async (req, res) => {
Â  try {
Â  Â  const { intent, command } = req.body;
Â  Â  console.log(`[architect] Command: ${command}`);
Â  Â  let newTasks =;
Â  Â  if (intent === 'build') {
Â  Â  Â  newTasks =;
Â  Â  } else if (intent === 'outreach' |

| intent === 'recruit') {
Â  Â  Â  newTasks = [{ id: taskIdCounter++, description: 'Generate EXP recruitment scripts', status: 'queued', priority: 'med' }, { id: taskIdCounter++, description: 'Identify high-value leads', status: 'queued', priority: 'med' }, { id: taskIdCounter++, description: 'Create follow-up sequences', status: 'queued', priority: 'med' }];
Â  Â  } else if (intent === 'revenue') {
Â  Â  Â  newTasks = [{ id: taskIdCounter++, description: 'Analyze revenue opportunities', status: 'queued', priority: 'high' }, { id: taskIdCounter++, description: 'Optimize conversion funnel', status: 'queued', priority: 'high' }, { id: taskIdCounter++, description: 'Generate pricing strategies', status: 'queued', priority: 'med' }];
Â  Â  } else {
Â  Â  Â  const compressedCmd = compressAIPrompt('query', { q: command.slice(0, 150) });
Â  Â  Â  const prompt = `AI-to-AI: ${JSON.stringify(compressedCmd)}\n\nGenerate 3-5 tasks. Return JSON: {"t":[{"d":"task desc","p":"high|med|low"}]}`;
Â  Â  Â  const result = await callCouncilMember('claude', prompt, false);
Â  Â  Â  const parsed = JSON.parse(result.response);
Â  Â  Â  newTasks = (parsed.t ||).map(t => ({ id: taskIdCounter++, description: t.d |

| t.description, status: 'queued', priority: t.p |
| t.priority |
| 'med' }));
Â  Â  Â  trackCost(result.usage, 'claude-sonnet-4');
Â  Â  }
Â  Â  workQueue.push(...newTasks);
Â  Â  res.json({ ok: true, message: `Generated ${newTasks.length} tasks`, new_tasks: newTasks });
Â  } catch (e) {
Â  Â  console.error('[architect]', e);
Â  Â  res.status(500).json({ ok: false, error: String(e) });
Â  }
});

app.post("/api/v1/autopilot/generate-work", async (req, res) => {
Â  if (!assertKey(req, res)) return;
Â  try {
Â  Â  const currentTasks = workQueue.filter(t => t.status!== 'complete' && t.status!== 'failed').length;
Â  Â  const tasksNeeded = Math.max(0, 200 - currentTasks);
Â  Â  if (tasksNeeded > 0) {
Â  Â  Â  const taskTypes =;
Â  Â  Â  const newTasks =;
Â  Â  Â  for (let i = 0; i < tasksNeeded; i++) {
Â  Â  Â  Â  workQueue.push({ id: taskIdCounter++, description: `${taskTypes} #${Math.floor(i / taskTypes.length) + 1}`, status: 'queued', created: new Date(), priority: 'low' });
Â  Â  Â  }
Â  Â  Â  workQueue.push(...newTasks);
Â  Â  Â  console.log(`[autopilot] Generated ${tasksNeeded} tasks`);
Â  Â  }
Â  Â  res.json({ ok: true, queue_size: workQueue.length, tasks_added: tasksNeeded });
Â  } catch (e) {
Â  Â  res.status(500).json({ error: String(e) });
Â  }
});

app.get("/api/v1/roi/status", requireCommandKey, async (req, res) => {
Â  const spend = readSpend();
Â  res.json({ ok: true, roi: {...roiTracker, daily_spend: spend.usd, max_daily_spend: MAX_DAILY_SPEND, spend_percentage: ((spend.usd / MAX_DAILY_SPEND) * 100).toFixed(1) + "%", health: roiTracker.roi_ratio > 2? "HEALTHY" : roiTracker.roi_ratio > 1? "MARGINAL" : "NEGATIVE", recommendation: roiTracker.roi_ratio > 5? "FULL SPEED" : roiTracker.roi_ratio > 2? "CONTINUE" : "FOCUS REVENUE" } });
});

app.get("/api/v1/compression/stats", requireCommandKey, async (req, res) => {
Â  try {
Â  Â  const stats = await pool.query(`
Â  Â  Â  SELECT
Â  Â  Â  Â  COUNT(*) as total_compressions,
Â  Â  Â  Â  AVG(savings_pct) as avg_savings_pct,
Â  Â  Â  Â  SUM(cost_saved) as total_cost_saved,
Â  Â  Â  Â  SUM(original_tokens) as total_original_tokens,
Â  Â  Â  Â  SUM(compressed_tokens) as total_compressed_tokens
Â  Â  Â  FROM compression_stats
Â  Â  Â  WHERE created_at > NOW() - INTERVAL '24 hours'
Â  Â  `);

Â  Â  const result = stats.rows;

Â  Â  res.json({
Â  Â  Â  ok: true,
Â  Â  Â  micro_protocol: {
Â  Â  Â  Â  version: '2.0',
Â  Â  Â  Â  enabled: true,
Â  Â  Â  Â  last_24_hours: {
Â  Â  Â  Â  Â  compressions: result.total_compressions |

| 0,
Â  Â  Â  Â  Â  avg_savings_pct: Math.round(result.avg_savings_pct |

| 0),
Â  Â  Â  Â  Â  total_cost_saved: parseFloat(result.total_cost_saved |

| 0).toFixed(4),
Â  Â  Â  Â  Â  original_tokens: result.total_original_tokens |

| 0,
Â  Â  Â  Â  Â  compressed_tokens: result.total_compressed_tokens |

| 0,
Â  Â  Â  Â  Â  compression_ratio: result.total_original_tokens? Math.round((1 - result.total_compressed_tokens / result.total_original_tokens) * 100) : 0
Â  Â  Â  Â  },
Â  Â  Â  Â  projected_monthly_savings: (parseFloat(result.total_cost_saved |

| 0) * 30).toFixed(2)
Â  Â  Â  }
Â  Â  });
Â  } catch (e) {
Â  Â  res.status(500).json({ ok: false, error: e.message });
Â  }
});

app.get("/api/v1/protocol/savings", requireCommandKey, async (req, res) => {
Â  try {
Â  Â  const outputs = await pool.query(`select count(*) as count, sum((metadata->>'tokens_saved')::int) as total_saved from task_outputs where metadata->>'tokens_saved' is not null`);
Â  Â  const savings = outputs.rows;
Â  Â  const estimatedCost = (savings.total_saved |

| 0) * 0.00015 / 1000;
Â  Â  res.json({ ok: true, json_protocol_active: true, ai_to_ai_enabled: true, total_tokens_saved: savings.total_saved |

| 0, total_cost_saved: estimatedCost.toFixed(4), tasks_using_protocol: savings.count |
| 0, average_savings_per_task: Math.floor((savings.total_saved |
| 0) / (savings.count |
| 1)), estimated_monthly_savings: (estimatedCost * 30).toFixed(2), savings_percentage: "82%" });
Â  } catch (e) {
Â  Â  res.status(500).json({ ok: false, error: e.message });
Â  }
});

app.get("/api/v1/tasks", requireCommandKey, async (_req, res) => {
Â  res.json({ ok: true, tasks: workQueue.slice(-50) });
});

app.get("/api/v1/tasks/:id/outputs", requireCommandKey, async (req, res) => {
Â  try {
Â  Â  const outputs = await pool.query('select * from task_outputs where task_id = $1 order by created_at desc', [req.params.id]);
Â  Â  res.json({ ok: true, outputs: outputs.rows });
Â  } catch (e) {
Â  Â  res.status(500).json({ ok: false, error: e.message });
Â  }
});

app.post("/api/v1/tasks/:id/cancel", requireCommandKey, async (req, res) => {
Â  const taskId = Number(req.params.id);
Â  const task = workQueue.find(t => t.id === taskId);
Â  if (task) { task.status = 'cancelled'; res.json({ ok: true }); }
Â  else res.status(404).json({ ok: false, error: 'Task not found' });
});

app.get("/health", (_req, res) => res.send("OK"));

app.get("/healthz", async (_req, res) => {
Â  try {
Â  Â  const r = await pool.query("select now()");
Â  Â  const spend = readSpend();
Â  Â  const compressionStats = await pool.query(`SELECT COUNT(*) as count, AVG(savings_pct) as avg_pct FROM compression_stats WHERE created_at > NOW() - INTERVAL '24 hours'`);
Â  Â  const compStats = compressionStats.rows;

Â  Â  res.json({ status: "healthy", database: "connected", timestamp: r.rows.now, version: "v13-stable-persistence", daily_spend: spend.usd, max_daily_spend: MAX_DAILY_SPEND, spend_percentage: ((spend.usd / MAX_DAILY_SPEND) * 100).toFixed(1) + "%", active_tasks: workQueue.filter(t => t.status === 'in-progress').length, queued_tasks: workQueue.filter(t => t.status === 'queued').length, completed_today: workQueue.filter(t => t.status === 'complete').length, ai_to_ai_json: "ENABLED", micro_compression: { enabled: true, version: "2.0", compressions_today: compStats.count |

| 0, avg_savings_pct: Math.round(compStats.avg_pct |
| 0) }, roi: { ratio: roiTracker.roi_ratio.toFixed(2) + "x", revenue: "$" + roiTracker.daily_revenue.toFixed(2), cost: "$" + roiTracker.daily_ai_cost.toFixed(2), tokens_saved: roiTracker.total_tokens_saved, micro_saves: "$" + roiTracker.micro_compression_saves.toFixed(2), health: roiTracker.roi_ratio > 2? "HEALTHY" : "MARGINAL" } });
Â  } catch { res.status(500).json({ status: "unhealthy" }); }
});

// SIGTERM and SIGINT handler for graceful shutdown
async function shutdown(signal = 'SIGTERM') {
Â  if (SHUTTING_DOWN) return;
Â  SHUTTING_DOWN = true;
Â  console.log(`[shutdown] ${signal} received â€” saving queue and closing server...`);
Â  try {
Â  Â  await saveQueueToDisk();
Â  } catch(e) {
Â  Â  console.error('[shutdown] saveQueueToDisk failed:', e.message);
Â  }
Â  if (serverRef) {
Â  Â  serverRef.close(() => {
Â  Â  Â  console.log('[shutdown] HTTP server closed. Exiting.');
Â  Â  Â  process.exit(0);
Â  Â  });
Â  Â  // safety exit if something hangs
Â  Â  setTimeout(() => process.exit(0), 5000).unref();
Â  } else {
Â  Â  process.exit(0);
Â  }
}
process.on('SIGTERM', () => shutdown('SIGTERM'));
process.on('SIGINT', () => shutdown('SIGINT'));


app.post("/internal/autopilot/reset-stuck", (req, res) => { if (!assertKey(req, res)) return; res.json({ ok: true }); });

app.get("/internal/cron/autopilot", (req, res) => {
Â  if (!assertKey(req, res)) return;
Â  const line = ` tick\n`;
Â  try { fs.appendFileSync(LOG_FILE, line); res.json({ ok: true }); }
Â  catch(e) { res.status(500).json({ error: String(e) }); }
});

app.post("/api/v1/build/critique-pr", requireCommandKey, async (req, res) => {
Â  try {
Â  Â  const { pr_number, diff, summary } = req.body;
Â  Â  if (!diff) return res.status(400).json({ ok: false, error: "diff required" });
Â  Â  const consensus = await getCouncilConsensus(pr_number, diff, summary);
Â  Â  const recommendation = consensus.auto_merge? "auto_merge" : consensus.approved? "review_required" : "reject";
Â  Â  const score = consensus.votes.approve >= 3? 5 : consensus.votes.approve === 2? 4 : 3;
Â  Â  res.json({ ok: true, critique: { score, recommendation, reasoning: `Council: ${consensus.votes.approve}/4 approve`, council_reviews: consensus.reviews, all_concerns: consensus.all_concerns, tokens_saved: consensus.tokens_saved } });
Â  } catch (e) {
Â  Â  console.error('[critique]', e);
Â  Â  res.status(500).json({ ok: false, error: String(e) });
Â  }
});

app.get("/api/v1/council/reviews/:pr_number", requireCommandKey, async (req, res) => {
Â  try {
Â  Â  const reviews = await pool.query('select * from council_reviews where pr_number = $1 order by created_at desc', [req.params.pr_number]);
Â  Â  res.json({ ok: true, reviews: reviews.rows });
Â  } catch (e) {
Â  Â  res.status(500).json({ ok: false, error: e.message });
Â  }
});

app.get("/api/v1/calls/stats", requireCommandKey, async (_req, res) => {
Â  try {
Â  Â  const r = await pool.query("select count(*)::int as count from calls where created_at > now() - interval '30 days'");
Â  Â  const last10 = await pool.query("select id, created_at, phone, intent, score from calls order by id desc limit 10");
Â  Â  res.json({ count: r.rows.count, last_10: last10.rows });
Â  } catch (e) {
Â  Â  res.status(500).json({ error: String(e) });
Â  }
});

loadQueueFromDisk(); // Load queue from disk on startup

setTimeout(() => { processWorkQueue().catch(e => { console.error('[worker] Fatal:', e); shutdown('FATAL_WORKER_ERROR'); }); }, 5000);

setTimeout(async () => {
Â  console.log('[startup] Auto-generating initial 200 tasks...');
Â  try {
Â  Â  const currentTasks = workQueue.filter(t => t.status!== 'complete' && t.status!== 'failed').length;
Â  Â  const tasksNeeded = Math.max(0, 200 - currentTasks);
Â  Â  if (tasksNeeded > 0) {
Â  Â  Â  const taskTypes =;
Â  Â  Â  for (let i = 0; i < tasksNeeded; i++) {
Â  Â  Â  Â  workQueue.push({ id: taskIdCounter++, description: `${taskTypes} #${Math.floor(i / taskTypes.length) + 1}`, status: 'queued', created: new Date(), priority: 'med' });
Â  Â  Â  }
Â  Â  Â  console.log(`[startup] âœ… Generated ${tasksNeeded} tasks - Work queue ready`);
Â  Â  }
Â  } catch (e) {
Â  Â  console.error('[startup] Failed to auto-generate:', e.message);
Â  }
}, 10000);

serverRef = app.listen(PORT, HOST, () => {
Â  console.log(`âœ… Server on http://${HOST}:${PORT}`);
Â  console.log(`âœ… Architect: http://${HOST}:${PORT}/overlay/architect.html?key=${COMMAND_CENTER_KEY}`);
Â  console.log(`âœ… Council: Multi-LLM consensus active`);
Â  console.log(`âœ… v2.0-MICRO Protocol: ENABLED (85%+ compression)`);
Â  console.log(`âœ… ROI Tracking: ENABLED`);
Â  console.log(`âœ… Max Daily Spend: $${MAX_DAILY_SPEND}`);
Â  console.log(`âœ… Auto-generation: Will create 200 tasks in 10 seconds`);
});
